{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d89840c266e24ef78d7d65a196c4ffa4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a865c737e2944dbc9da8e5a4a57051d0",
              "IPY_MODEL_da949447e93a414ca2a3d6e3788be4a5",
              "IPY_MODEL_e8694e6923434f3eb823442b51982d82"
            ],
            "layout": "IPY_MODEL_cf257cac8c5f4b298882f64a4162cd52"
          }
        },
        "a865c737e2944dbc9da8e5a4a57051d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_383a7593d3e346df92573c3fa159de4c",
            "placeholder": "​",
            "style": "IPY_MODEL_8e2d1fe51df84a5ea9343e6d13a13136",
            "value": "Epoch 1/80: 100%"
          }
        },
        "da949447e93a414ca2a3d6e3788be4a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c334e8ca0ecc47ad8f4788d357111218",
            "max": 31,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_de689220d48e474a83e2c6a34b01f692",
            "value": 31
          }
        },
        "e8694e6923434f3eb823442b51982d82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab82449e4585468c8ce4a21f2d2435a9",
            "placeholder": "​",
            "style": "IPY_MODEL_a0f45abef42a45e48ca664e2b36a0df9",
            "value": " 31/31 [00:13&lt;00:00,  2.65it/s, G=1.1599, D=2.4785, α=0.013]"
          }
        },
        "cf257cac8c5f4b298882f64a4162cd52": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "383a7593d3e346df92573c3fa159de4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e2d1fe51df84a5ea9343e6d13a13136": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c334e8ca0ecc47ad8f4788d357111218": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de689220d48e474a83e2c6a34b01f692": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ab82449e4585468c8ce4a21f2d2435a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0f45abef42a45e48ca664e2b36a0df9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ca2a5cb20d2948ad90b828d73f40c2c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7e4d2d1e5a4c4c4fac427f46e9f2bc7f",
              "IPY_MODEL_9661e5d1c15c4635bff6d946795a5672",
              "IPY_MODEL_d9bc8fd1639e484caeac3dd248fe7543"
            ],
            "layout": "IPY_MODEL_b342c35e7fc84be1b01828cf07881316"
          }
        },
        "7e4d2d1e5a4c4c4fac427f46e9f2bc7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_37a11764082c43dabd4437c67d5e0424",
            "placeholder": "​",
            "style": "IPY_MODEL_0752aaf4e2744a91bebe4eb994e6456d",
            "value": "Epoch 2/80: 100%"
          }
        },
        "9661e5d1c15c4635bff6d946795a5672": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aaaa3bf2782f404481b3edadf09088c1",
            "max": 31,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2c6b38d24b034fdfae1e3d25f39cc70c",
            "value": 31
          }
        },
        "d9bc8fd1639e484caeac3dd248fe7543": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b48f03043dcf458dab661bf00572f76c",
            "placeholder": "​",
            "style": "IPY_MODEL_e05f8bcae3f646e9ad2a9b218b359e2b",
            "value": " 31/31 [00:12&lt;00:00,  2.65it/s, G=1.1648, D=1.9053, α=0.017]"
          }
        },
        "b342c35e7fc84be1b01828cf07881316": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37a11764082c43dabd4437c67d5e0424": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0752aaf4e2744a91bebe4eb994e6456d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aaaa3bf2782f404481b3edadf09088c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c6b38d24b034fdfae1e3d25f39cc70c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b48f03043dcf458dab661bf00572f76c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e05f8bcae3f646e9ad2a9b218b359e2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "45664f4e8442455c8a0873002c6eb5f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7c78c99d540f478e83479399029e33be",
              "IPY_MODEL_d502220102094423a325299cd88dd30a",
              "IPY_MODEL_6116ed8854f442c18a2f3c5635353ec1"
            ],
            "layout": "IPY_MODEL_f212b1bcbe4c4f3ba3589419ddf9b877"
          }
        },
        "7c78c99d540f478e83479399029e33be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76f37db6c413471b80ccfe5c44d9c875",
            "placeholder": "​",
            "style": "IPY_MODEL_1754c361997841e9841a5dfaae392d5c",
            "value": "Epoch 3/80: 100%"
          }
        },
        "d502220102094423a325299cd88dd30a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cef34c12618d4c9383b3c2423cd252a1",
            "max": 31,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_22323f72217746d799781b33a6e745c9",
            "value": 31
          }
        },
        "6116ed8854f442c18a2f3c5635353ec1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_623b6937679a4040b2a371b92113a1cf",
            "placeholder": "​",
            "style": "IPY_MODEL_de45bcc2b9c346dfad2e34bb3fb6b296",
            "value": " 31/31 [00:12&lt;00:00,  2.65it/s, G=1.2460, D=1.7344, α=0.020]"
          }
        },
        "f212b1bcbe4c4f3ba3589419ddf9b877": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76f37db6c413471b80ccfe5c44d9c875": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1754c361997841e9841a5dfaae392d5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cef34c12618d4c9383b3c2423cd252a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22323f72217746d799781b33a6e745c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "623b6937679a4040b2a371b92113a1cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de45bcc2b9c346dfad2e34bb3fb6b296": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "706ef876220c4fd8a67a21d2fe903d27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c4cbef4a0aac4587b1e193e27f99e5e1",
              "IPY_MODEL_b0d49e53f21447b9835c36bc9d8f6e8c",
              "IPY_MODEL_5572034d0bf14ca4adb600f8feff367a"
            ],
            "layout": "IPY_MODEL_2d40e6ce3d8b4144abab1929aeefb3d8"
          }
        },
        "c4cbef4a0aac4587b1e193e27f99e5e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_211a8fe7d3594b28b4f52f0938cc1bc1",
            "placeholder": "​",
            "style": "IPY_MODEL_50cfa09b5ea94930895dc5a8a6f0557a",
            "value": "Epoch 4/80:  45%"
          }
        },
        "b0d49e53f21447b9835c36bc9d8f6e8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a43feec37524494da424f9894444a88e",
            "max": 31,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ecc97477900e4fedb27645ad5b8818c1",
            "value": 14
          }
        },
        "5572034d0bf14ca4adb600f8feff367a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24bb2370f911479283209f76e5682ec6",
            "placeholder": "​",
            "style": "IPY_MODEL_5922d903d32c4a74931eb8e4134e01dc",
            "value": " 14/31 [00:05&lt;00:06,  2.63it/s, G=1.1367, D=1.7373, α=0.021]"
          }
        },
        "2d40e6ce3d8b4144abab1929aeefb3d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "211a8fe7d3594b28b4f52f0938cc1bc1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50cfa09b5ea94930895dc5a8a6f0557a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a43feec37524494da424f9894444a88e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ecc97477900e4fedb27645ad5b8818c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "24bb2370f911479283209f76e5682ec6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5922d903d32c4a74931eb8e4134e01dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RMMlqkYC0NMw",
        "outputId": "c77a740d-92d3-495a-9b9c-870f5d56f6dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Unzip the dataset ---\n",
        "# IMPORTANT: Update this path to match the location of your zip file in Drive.\n",
        "zip_path = '/content/drive/MyDrive/ColabNotebooks/Vision/inpainting/ffhq256_10ksubset.zip'\n",
        "\n",
        "# The destination folder in the local Colab environment.\n",
        "destination_path = '/content'\n",
        "\n",
        "print(\"Unzipping dataset...\")\n",
        "# The -q flag makes the output cleaner (quiet mode)\n",
        "!unzip -q {zip_path} -d {destination_path}\n",
        "\n",
        "print(f\"✅ Dataset unzipped to {destination_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_rH_lvB0Vwl",
        "outputId": "8d800701-bc06-4039-b936-6f4241f1ded0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unzipping dataset...\n",
            "✅ Dataset unzipped to /content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install\n",
        "!pip -q install pytorch_wavelets torchmetrics lpips torch-fidelity"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YEDQAJB00Yzr",
        "outputId": "f4697eb2-44fa-42f8-c0e3-be203a1a1794"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/54.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.9/54.9 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/983.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.0/983.0 kB\u001b[0m \u001b[31m58.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.8/53.8 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m81.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m97.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m64.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m37.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m94.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "import torch._dynamo\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "from torch.nn.utils import spectral_norm\n",
        "from torchvision.utils import save_image, make_grid\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import time\n",
        "import random\n",
        "import math\n",
        "from tqdm.auto import tqdm\n",
        "from tqdm.autonotebook import tqdm\n",
        "import os\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torchmetrics\n",
        "from torchmetrics.image.fid import FrechetInceptionDistance\n",
        "import lpips\n",
        "\n",
        "import torch.fft\n",
        "from pytorch_wavelets import DWTForward\n",
        "from einops import rearrange\n",
        "\n",
        "# Enable TensorFloat32\n",
        "torch.set_float32_matmul_precision('high')\n",
        "\n",
        "# --- Configuration & Hyperparameters ---\n",
        "\n",
        "# Set the path to your image folder in Google Drive\n",
        "# IMPORTANT: Update this path to match where you saved your dataset.\n",
        "DATASET_PATH = '/content/ffhq_subset_10k'\n",
        "NUM_IMAGES_TO_USE_CNN = 10000\n",
        "NUM_IMAGES_TO_USE_GAN = 1000\n",
        "\n",
        "# Training settings\n",
        "NUM_EPOCHS_CNN = 40\n",
        "NUM_EPOCHS_GAN = 200\n",
        "LEARNING_RATE = 1e-4\n",
        "BATCH_SIZE = 4\n",
        "\n",
        "# Set the device (use GPU if available)\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {DEVICE}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9lOjwd_0bEa",
        "outputId": "f1744ada-8200-40d2-99d8-446b4d2b3d27"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class FFHQDataset(Dataset):\n",
        "    \"\"\"Custom PyTorch Dataset for loading FFHQ images.\"\"\"\n",
        "    def __init__(self, img_dir, transform=None, num_images=None): # Add num_images parameter\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            img_dir (string): Directory with all the images.\n",
        "            transform (callable, optional): Optional transform to be applied on a sample.\n",
        "            num_images (int, optional): Number of images to use. If None, use all images.\n",
        "        \"\"\"\n",
        "        # Find all files with .png or .jpg extension\n",
        "        self.img_paths = glob.glob(os.path.join(img_dir, '*.png'))\n",
        "        self.img_paths.extend(glob.glob(os.path.join(img_dir, '*.jpg')))\n",
        "        self.transform = transform\n",
        "\n",
        "        if num_images:\n",
        "            # If a number is specified, shuffle all paths and take a random subset\n",
        "            random.shuffle(self.img_paths)\n",
        "            self.img_paths = self.img_paths[:num_images]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.img_paths[idx]\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image\n",
        "\n",
        "# Your transform definition remains the same\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "])"
      ],
      "metadata": {
        "id": "_8c97qH00lzs"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tensor_to_image(tensor):\n",
        "    \"\"\"\n",
        "    Converts a PyTorch tensor to a displayable NumPy image.\n",
        "    It denormalizes, moves to CPU, and changes dimension order.\n",
        "    \"\"\"\n",
        "    # Denormalize the image from [-1, 1] to [0, 1]\n",
        "    image = tensor * 0.5 + 0.5\n",
        "    # Move tensor to CPU and convert to NumPy array\n",
        "    image = image.cpu().numpy()\n",
        "    # Transpose dimensions from (C, H, W) to (H, W, C) for plotting\n",
        "    image = image.transpose(1, 2, 0)\n",
        "    # Clip values to be in the valid [0, 1] range for images\n",
        "    image = np.clip(image, 0, 1)\n",
        "    return image"
      ],
      "metadata": {
        "id": "rmdlduRN0oos"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_mask(image, mask_percentage=0.025):\n",
        "    \"\"\"\n",
        "    Creates masks that are more likely to cover facial features.\n",
        "    \"\"\"\n",
        "    batch_size, _, height, width = image.shape\n",
        "    mask = torch.ones_like(image)\n",
        "\n",
        "    # Face regions typically in center 60% of image\n",
        "    center_bias = 0.3  # 30% border on each side\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        mask_h = int(np.sqrt(height * width * mask_percentage))\n",
        "        mask_w = mask_h\n",
        "\n",
        "        # Bias towards center\n",
        "        top_min = int(height * center_bias)\n",
        "        top_max = int(height * (1 - center_bias)) - mask_h\n",
        "        left_min = int(width * center_bias)\n",
        "        left_max = int(width * (1 - center_bias)) - mask_w\n",
        "\n",
        "        top = np.random.randint(top_min, max(top_min + 1, top_max))\n",
        "        left = np.random.randint(left_min, max(left_min + 1, left_max))\n",
        "\n",
        "        mask[i, :, top:top+mask_h, left:left+mask_w] = 0\n",
        "\n",
        "    masked_image = image * mask\n",
        "    return masked_image, mask"
      ],
      "metadata": {
        "id": "Y5Jjq2iV0rI5"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SelfAttention(nn.Module):\n",
        "    \"\"\" A simple self-attention layer \"\"\"\n",
        "    def __init__(self, channels):\n",
        "        super().__init__()\n",
        "        self.query = nn.Conv2d(channels, channels // 8, 1)\n",
        "        self.key   = nn.Conv2d(channels, channels // 8, 1)\n",
        "        self.value = nn.Conv2d(channels, channels, 1)\n",
        "        self.gamma = nn.Parameter(torch.zeros(1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size, C, width, height = x.size()\n",
        "        q = self.query(x).view(batch_size, -1, width * height).permute(0, 2, 1)\n",
        "        k = self.key(x).view(batch_size, -1, width * height)\n",
        "        v = self.value(x).view(batch_size, -1, width * height)\n",
        "\n",
        "        attention_map = F.softmax(torch.bmm(q, k), dim=-1)\n",
        "\n",
        "        out = torch.bmm(v, attention_map.permute(0, 2, 1))\n",
        "        out = out.view(batch_size, C, width, height)\n",
        "\n",
        "        return self.gamma * out + x # Add skip connection\n",
        "\n",
        "class UpsampleBlock(nn.Module):\n",
        "    \"\"\"An upsampling block using Conv2d and PixelShuffle.\"\"\"\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        # The Conv2d layer produces 4x the channels for a 2x upscale\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels * 4, kernel_size=3, padding=1)\n",
        "        self.pixel_shuffle = nn.PixelShuffle(2) # Rearranges channels to upscale by 2x\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.relu(self.pixel_shuffle(self.conv(x)))\n",
        "\n",
        "class GatedConv2d(nn.Module):\n",
        "    \"\"\"\n",
        "    A Gated Convolutional Layer.\n",
        "    It learns a dynamic feature mask for each channel at every location.\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1):\n",
        "        super().__init__()\n",
        "        # Convolution for the features\n",
        "        self.conv_feature = nn.Conv2d(\n",
        "            in_channels, out_channels, kernel_size, stride, padding, dilation\n",
        "        )\n",
        "        # Convolution for the gating mechanism\n",
        "        self.conv_gate = nn.Conv2d(\n",
        "            in_channels, out_channels, kernel_size, stride, padding, dilation\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Get the features and the gate\n",
        "        features = self.conv_feature(x)\n",
        "        gate = torch.sigmoid(self.conv_gate(x)) # Gate values are between 0 and 1\n",
        "\n",
        "        # Element-wise multiplication to apply the learned gate\n",
        "        return features * gate\n",
        "\n",
        "class GatedResidualBlock(nn.Module):\n",
        "    \"\"\"A Residual Block that uses Gated Convolutions.\"\"\"\n",
        "    def __init__(self, channels, dilation=1):\n",
        "        super().__init__()\n",
        "        padding = dilation\n",
        "\n",
        "        # Replace nn.Conv2d with GatedConv2d\n",
        "        self.conv1 = GatedConv2d(channels, channels, kernel_size=3, padding=padding, dilation=dilation)\n",
        "        self.bn1 = nn.BatchNorm2d(channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = GatedConv2d(channels, channels, kernel_size=3, padding=padding, dilation=dilation)\n",
        "        self.bn2 = nn.BatchNorm2d(channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = out + residual  # Residual connection\n",
        "        out = self.relu(out)\n",
        "        return out\n",
        "\n",
        "class UNetSR(nn.Module):\n",
        "    \"\"\"\n",
        "    A U-Net architecture with corrected channel dimensions for the decoder.\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels=4, out_channels=3, num_channels=64):\n",
        "        super().__init__()\n",
        "\n",
        "        # --- Initial Convolution ---\n",
        "        self.init_conv = nn.Conv2d(in_channels, num_channels, kernel_size=3, padding=1)\n",
        "\n",
        "        # --- Encoder Path ---\n",
        "        self.enc1 = GatedResidualBlock(num_channels, dilation=1)\n",
        "        self.enc2 = GatedResidualBlock(num_channels, dilation=1)\n",
        "        self.pool = nn.MaxPool2d(2)\n",
        "\n",
        "        # --- Bottleneck with Dilation and Attention ---\n",
        "        self.bottleneck = nn.Sequential(\n",
        "            GatedResidualBlock(num_channels, dilation=2),\n",
        "            # SelfAttention(num_channels), # Add attention layer\n",
        "            GatedResidualBlock(num_channels, dilation=4)\n",
        "        )\n",
        "\n",
        "        # --- Decoder Path ---\n",
        "        self.upconv2 = UpsampleBlock(num_channels, num_channels)\n",
        "        # Input channels = upsampled (64) + skip connection from e2 (64) = 128\n",
        "        self.dec2 = GatedResidualBlock(num_channels * 2, dilation=1)\n",
        "\n",
        "        self.upconv1 = UpsampleBlock(num_channels * 2, num_channels)\n",
        "        # Input channels = upsampled (64) + skip connection from e1 (64) = 128\n",
        "        self.dec1 = GatedResidualBlock(num_channels * 2, dilation=1)\n",
        "\n",
        "        # --- Final Output Layer ---\n",
        "        # The input to this layer comes from dec1, which outputs 128 channels.\n",
        "        self.out_conv = nn.Conv2d(num_channels * 2, out_channels, kernel_size=3, padding=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Initial feature extraction\n",
        "        x0 = self.init_conv(x)\n",
        "\n",
        "        # Encoder\n",
        "        e1 = self.enc1(x0)\n",
        "        p1 = self.pool(e1)\n",
        "\n",
        "        e2 = self.enc2(p1)\n",
        "        p2 = self.pool(e2)\n",
        "\n",
        "        # Bottleneck\n",
        "        b = self.bottleneck(p2)\n",
        "\n",
        "        # Decoder with Skip Connections\n",
        "        d2 = self.upconv2(b)\n",
        "        d2 = torch.cat([d2, e2], dim=1)\n",
        "        d2 = self.dec2(d2)\n",
        "\n",
        "        d1 = self.upconv1(d2)\n",
        "        d1 = torch.cat([d1, e1], dim=1)\n",
        "        d1 = self.dec1(d1)\n",
        "\n",
        "        # Final Output\n",
        "        out = self.out_conv(d1)\n",
        "\n",
        "        return torch.tanh(out)"
      ],
      "metadata": {
        "id": "loNrcp9a1w6A"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Create the main dataset ---\n",
        "# This should use the LARGER number of images you intend to work with.\n",
        "# Let's assume NUM_IMAGES_TO_USE_CNN is the total pool of images.\n",
        "print(\"Creating the main dataset...\")\n",
        "full_dataset = FFHQDataset(\n",
        "    img_dir=DATASET_PATH,\n",
        "    transform=transform,\n",
        "    num_images=NUM_IMAGES_TO_USE_CNN # Use the total number of images available for the experiment\n",
        ")\n",
        "print(f\"✅ Main dataset created with {len(full_dataset)} images.\")\n",
        "\n",
        "# --- 2. Split the dataset into Training, Validation, and Test sets ---\n",
        "print(\"\\nSplitting data into training, validation, and test sets...\")\n",
        "dataset_size = len(full_dataset)\n",
        "indices = list(range(dataset_size))\n",
        "np.random.seed(42) # for reproducibility\n",
        "np.random.shuffle(indices)\n",
        "\n",
        "# Define split points for an 80/10/10 split\n",
        "train_split = int(np.floor(0.8 * dataset_size))\n",
        "val_split = int(np.floor(0.9 * dataset_size))\n",
        "\n",
        "# Create indices for each set\n",
        "train_indices = indices[:train_split]\n",
        "val_indices = indices[train_split:val_split]\n",
        "test_indices = indices[val_split:]\n",
        "\n",
        "# Create PyTorch Subsets\n",
        "train_data = Subset(full_dataset, train_indices)\n",
        "val_data = Subset(full_dataset, val_indices)\n",
        "test_data = Subset(full_dataset, test_indices)\n",
        "\n",
        "print(f\"✅ Training set size: {len(train_data)}\")\n",
        "print(f\"✅ Validation set size: {len(val_data)}\")\n",
        "print(f\"✅ Test set size: {len(test_data)}\")\n",
        "\n",
        "# --- 3. Create the Diffusion Model's training subset ---\n",
        "# This should be a subset of the TRAINING data.\n",
        "print(\"\\nCreating a subset of the training data for the GAN model...\")\n",
        "gan_indices = train_indices[:NUM_IMAGES_TO_USE_GAN] # Take from the start of shuffled train indices\n",
        "gan_data = Subset(full_dataset, gan_indices)\n",
        "print(f\"✅ Diffusion training set size: {len(gan_data)}\")\n",
        "\n",
        "\n",
        "# --- 4. Create DataLoaders for each set ---\n",
        "print(\"\\nCreating DataLoaders...\")\n",
        "# The main CNN will now train on the 'train_data' subset\n",
        "cnn_dataloader = DataLoader(\n",
        "    train_data,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    num_workers=4,\n",
        "    pin_memory=True\n",
        ")\n",
        "# New DataLoader for validation\n",
        "val_dataloader = DataLoader(\n",
        "    val_data,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False, # No need to shuffle validation data\n",
        "    num_workers=4,\n",
        "    pin_memory=True\n",
        ")\n",
        "# New DataLoader for testing\n",
        "test_dataloader = DataLoader(\n",
        "    test_data,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False, # No need to shuffle test data\n",
        "    num_workers=4,\n",
        "    pin_memory=True\n",
        ")\n",
        "# GAN DataLoader uses its own subset of the training data\n",
        "gan_dataloader = DataLoader(\n",
        "    gan_data,\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    num_workers=4,\n",
        "    pin_memory=True,\n",
        "    drop_last=True\n",
        ")\n",
        "print(\"✅ All DataLoaders created.\")\n",
        "\n",
        "# --- 5. Initialize models and optimizers (unchanged) ---\n",
        "print(\"\\nInitializing models and optimizers...\")\n",
        "cnn_model = UNetSR().to(DEVICE)\n",
        "\n",
        "# Compile the models for a speed boost\n",
        "cnn_model = torch.compile(cnn_model)\n",
        "\n",
        "# Initialize optimizers\n",
        "optimizer_cnn = optim.Adam(cnn_model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "print(\"\\nSetup complete. Ready for CNN training!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZC-hFsMn0dbA",
        "outputId": "cdedc490-1934-4a9a-c34d-13f5fef27629"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating the main dataset...\n",
            "✅ Main dataset created with 10000 images.\n",
            "\n",
            "Splitting data into training, validation, and test sets...\n",
            "✅ Training set size: 8000\n",
            "✅ Validation set size: 1000\n",
            "✅ Test set size: 1000\n",
            "\n",
            "Creating a subset of the training data for the GAN model...\n",
            "✅ Diffusion training set size: 1000\n",
            "\n",
            "Creating DataLoaders...\n",
            "✅ All DataLoaders created.\n",
            "\n",
            "Initializing models and optimizers...\n",
            "\n",
            "Setup complete. Ready for CNN training!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# 1. GENERATOR - Residual Refinement Network\n",
        "# ============================================\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    \"\"\"Residual block with spectral normalization\"\"\"\n",
        "    def __init__(self, channels):\n",
        "        super().__init__()\n",
        "        self.conv1 = spectral_norm(nn.Conv2d(channels, channels, 3, 1, 1))\n",
        "        self.conv2 = spectral_norm(nn.Conv2d(channels, channels, 3, 1, 1))\n",
        "        self.norm1 = nn.InstanceNorm2d(channels)\n",
        "        self.norm2 = nn.InstanceNorm2d(channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        x = F.leaky_relu(self.norm1(self.conv1(x)), 0.2)\n",
        "        x = self.norm2(self.conv2(x))\n",
        "        return x + residual\n",
        "\n",
        "class SelfAttention(nn.Module):\n",
        "    \"\"\"Self-attention layer for capturing long-range dependencies\"\"\"\n",
        "    def __init__(self, channels):\n",
        "        super().__init__()\n",
        "        self.query = spectral_norm(nn.Conv2d(channels, channels // 8, 1))\n",
        "        self.key = spectral_norm(nn.Conv2d(channels, channels // 8, 1))\n",
        "        self.value = spectral_norm(nn.Conv2d(channels, channels, 1))\n",
        "        self.gamma = nn.Parameter(torch.zeros(1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, c, h, w = x.shape\n",
        "\n",
        "        q = self.query(x).view(b, -1, h * w).permute(0, 2, 1)\n",
        "        k = self.key(x).view(b, -1, h * w)\n",
        "        v = self.value(x).view(b, -1, h * w)\n",
        "\n",
        "        attention = F.softmax(torch.bmm(q, k), dim=-1)\n",
        "        out = torch.bmm(v, attention.permute(0, 2, 1))\n",
        "        out = out.view(b, c, h, w)\n",
        "\n",
        "        return self.gamma * out + x\n",
        "\n",
        "class RefinementGenerator(nn.Module):\n",
        "    \"\"\"Generator that refines CNN output\"\"\"\n",
        "    def __init__(self, in_channels=7, out_channels=3, base_channels=64):\n",
        "        super().__init__()\n",
        "\n",
        "        # Input: CNN output (3) + original masked (3) + mask (1) = 7 channels\n",
        "        self.encoder = nn.Sequential(\n",
        "            spectral_norm(nn.Conv2d(in_channels, base_channels, 7, 1, 3)),\n",
        "            nn.LeakyReLU(0.2, True)\n",
        "        )\n",
        "\n",
        "        # Downsampling\n",
        "        self.down1 = nn.Sequential(\n",
        "            spectral_norm(nn.Conv2d(base_channels, base_channels * 2, 4, 2, 1)),\n",
        "            nn.InstanceNorm2d(base_channels * 2),\n",
        "            nn.LeakyReLU(0.2, True)\n",
        "        )\n",
        "\n",
        "        self.down2 = nn.Sequential(\n",
        "            spectral_norm(nn.Conv2d(base_channels * 2, base_channels * 4, 4, 2, 1)),\n",
        "            nn.InstanceNorm2d(base_channels * 4),\n",
        "            nn.LeakyReLU(0.2, True)\n",
        "        )\n",
        "\n",
        "        # Residual blocks with attention\n",
        "        self.res_blocks = nn.Sequential(\n",
        "            ResidualBlock(base_channels * 4),\n",
        "            ResidualBlock(base_channels * 4),\n",
        "            SelfAttention(base_channels * 4),\n",
        "            ResidualBlock(base_channels * 4),\n",
        "            ResidualBlock(base_channels * 4),\n",
        "        )\n",
        "\n",
        "        # Upsampling\n",
        "        self.up1 = nn.Sequential(\n",
        "            spectral_norm(nn.ConvTranspose2d(base_channels * 4, base_channels * 2, 4, 2, 1)),\n",
        "            nn.InstanceNorm2d(base_channels * 2),\n",
        "            nn.LeakyReLU(0.2, True)\n",
        "        )\n",
        "\n",
        "        self.up2 = nn.Sequential(\n",
        "            spectral_norm(nn.ConvTranspose2d(base_channels * 2, base_channels, 4, 2, 1)),\n",
        "            nn.InstanceNorm2d(base_channels),\n",
        "            nn.LeakyReLU(0.2, True)\n",
        "        )\n",
        "\n",
        "        # Output residual\n",
        "        self.output = nn.Sequential(\n",
        "            spectral_norm(nn.Conv2d(base_channels, out_channels, 7, 1, 3)),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "        # Learnable residual weight\n",
        "        self.residual_weight = nn.Parameter(torch.tensor(0.01))\n",
        "\n",
        "    def forward(self, cnn_output, masked_image, mask):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            cnn_output: CNN's coarse prediction [B, 3, H, W]\n",
        "            masked_image: Original image with mask applied [B, 3, H, W]\n",
        "            mask: Binary mask [B, 1, H, W]\n",
        "        \"\"\"\n",
        "        # Concatenate inputs\n",
        "        x = torch.cat([cnn_output, masked_image, mask], dim=1)\n",
        "\n",
        "        # Encode\n",
        "        x = self.encoder(x)\n",
        "\n",
        "        # Downsample\n",
        "        d1 = self.down1(x)\n",
        "        d2 = self.down2(d1)\n",
        "\n",
        "        # Process with residual blocks\n",
        "        x = self.res_blocks(d2)\n",
        "\n",
        "        # Upsample with skip connections\n",
        "        x = self.up1(x)\n",
        "        x = self.up2(x + d1)  # Skip connection\n",
        "\n",
        "        # Generate residual\n",
        "        residual = self.output(x)\n",
        "\n",
        "        # Add weighted residual to CNN output\n",
        "        refined = cnn_output + self.residual_weight * residual\n",
        "\n",
        "        # Ensure output is in [-1, 1]\n",
        "        return torch.tanh(refined)"
      ],
      "metadata": {
        "id": "mSdcxtHr0yPW"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# 2. DISCRIMINATOR - Multi-scale PatchGAN\n",
        "# ============================================\n",
        "\n",
        "class MultiscaleDiscriminator(nn.Module):\n",
        "    \"\"\"Multi-scale discriminator for better gradient flow\"\"\"\n",
        "    def __init__(self, in_channels=3, base_channels=64, num_scales=3):\n",
        "        super().__init__()\n",
        "\n",
        "        self.num_scales = num_scales\n",
        "        self.discriminators = nn.ModuleList()\n",
        "\n",
        "        for _ in range(num_scales):\n",
        "            self.discriminators.append(self._make_discriminator(in_channels, base_channels))\n",
        "\n",
        "        self.downsample = nn.AvgPool2d(2)\n",
        "\n",
        "    def _make_discriminator(self, in_channels, base_channels):\n",
        "        return nn.Sequential(\n",
        "            spectral_norm(nn.Conv2d(in_channels, base_channels, 4, 2, 1)),\n",
        "            nn.LeakyReLU(0.2, True),\n",
        "\n",
        "            spectral_norm(nn.Conv2d(base_channels, base_channels * 2, 4, 2, 1)),\n",
        "            nn.InstanceNorm2d(base_channels * 2),\n",
        "            nn.LeakyReLU(0.2, True),\n",
        "\n",
        "            spectral_norm(nn.Conv2d(base_channels * 2, base_channels * 4, 4, 2, 1)),\n",
        "            nn.InstanceNorm2d(base_channels * 4),\n",
        "            nn.LeakyReLU(0.2, True),\n",
        "\n",
        "            spectral_norm(nn.Conv2d(base_channels * 4, base_channels * 8, 4, 1, 1)),\n",
        "            nn.InstanceNorm2d(base_channels * 8),\n",
        "            nn.LeakyReLU(0.2, True),\n",
        "\n",
        "            spectral_norm(nn.Conv2d(base_channels * 8, 1, 4, 1, 1))\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        outputs = []\n",
        "\n",
        "        for i in range(self.num_scales):\n",
        "            outputs.append(self.discriminators[i](x))\n",
        "            if i < self.num_scales - 1:\n",
        "                x = self.downsample(x)\n",
        "\n",
        "        return outputs"
      ],
      "metadata": {
        "id": "egVHxjX2000q"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# 3. LOSS FUNCTIONS\n",
        "# ============================================\n",
        "\n",
        "class PerceptualLoss(nn.Module):\n",
        "    \"\"\"VGG-based perceptual loss\"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        import torchvision.models as models\n",
        "        from torchvision.models import VGG19_Weights\n",
        "\n",
        "        vgg = models.vgg19(weights=VGG19_Weights.IMAGENET1K_V1).features\n",
        "\n",
        "        # Extract specific layers\n",
        "        self.layers = nn.ModuleList([\n",
        "            vgg[:4],   # relu1_2\n",
        "            vgg[4:9],  # relu2_2\n",
        "            vgg[9:18], # relu3_4\n",
        "        ])\n",
        "\n",
        "        # Freeze VGG\n",
        "        for param in self.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        # Normalization\n",
        "        self.register_buffer('mean', torch.tensor([0.485, 0.456, 0.406]).view(1, 3, 1, 1))\n",
        "        self.register_buffer('std', torch.tensor([0.229, 0.224, 0.225]).view(1, 3, 1, 1))\n",
        "\n",
        "    def forward(self, pred, target):\n",
        "        # Normalize from [-1, 1] to [0, 1]\n",
        "        pred = (pred + 1) / 2\n",
        "        target = (target + 1) / 2\n",
        "\n",
        "        # VGG normalization\n",
        "        pred = (pred - self.mean) / self.std\n",
        "        target = (target - self.mean) / self.std\n",
        "\n",
        "        loss = 0\n",
        "        x_pred, x_target = pred, target\n",
        "\n",
        "        for layer in self.layers:\n",
        "            x_pred = layer(x_pred)\n",
        "            x_target = layer(x_target)\n",
        "            loss += F.l1_loss(x_pred, x_target)\n",
        "\n",
        "        return loss\n",
        "\n",
        "def hinge_loss_d(real_pred, fake_pred):\n",
        "    \"\"\"Hinge loss for discriminator\"\"\"\n",
        "    loss = 0\n",
        "    for real_p, fake_p in zip(real_pred, fake_pred):\n",
        "        loss += torch.mean(F.relu(1 - real_p)) + torch.mean(F.relu(1 + fake_p))\n",
        "    return loss / len(real_pred)\n",
        "\n",
        "def hinge_loss_g(fake_pred):\n",
        "    \"\"\"Hinge loss for generator\"\"\"\n",
        "    loss = 0\n",
        "    for fake_p in fake_pred:\n",
        "        loss += -torch.mean(fake_p)\n",
        "    return loss / len(fake_pred)"
      ],
      "metadata": {
        "id": "SpWzgGcC03UW"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# 4. TRAINING FUNCTION\n",
        "# ============================================\n",
        "\n",
        "def train_gan(generator, discriminator, cnn_model, train_loader, val_loader,\n",
        "              num_epochs=80, device='cuda'):\n",
        "    \"\"\"Train the GAN for refinement\"\"\"\n",
        "\n",
        "    # Optimizers\n",
        "    g_optimizer = optim.Adam(generator.parameters(), lr=1e-4, betas=(0.0, 0.999))\n",
        "    d_optimizer = optim.Adam(discriminator.parameters(), lr=1e-4, betas=(0.0, 0.999))\n",
        "\n",
        "    # Add GradScalers for mixed precision\n",
        "    g_scaler = torch.amp.GradScaler('cuda')\n",
        "    d_scaler = torch.amp.GradScaler('cuda')\n",
        "\n",
        "    # Loss functions\n",
        "    l1_loss = nn.L1Loss()\n",
        "    perceptual_loss = PerceptualLoss().to(device)\n",
        "\n",
        "    # Training history\n",
        "    history = {'g_loss': [], 'd_loss': [], 'val_psnr': []}\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        generator.train()\n",
        "        discriminator.train()\n",
        "\n",
        "        epoch_g_loss = 0\n",
        "        epoch_d_loss = 0\n",
        "\n",
        "        pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}')\n",
        "        for batch_idx, batch in enumerate(pbar):\n",
        "            real_images = batch.to(device)\n",
        "            batch_size = real_images.size(0)\n",
        "\n",
        "            # Create masks and get CNN predictions\n",
        "            with torch.no_grad():\n",
        "                masked_images, masks = create_mask(real_images, mask_percentage=0.025)\n",
        "                masks = masks.to(device)\n",
        "\n",
        "                cnn_input = torch.cat([masked_images, masks[:, 0:1]], dim=1)\n",
        "                coarse_output = cnn_model(cnn_input)\n",
        "\n",
        "            # ==================\n",
        "            # Train Discriminator\n",
        "            # ==================\n",
        "            d_optimizer.zero_grad()\n",
        "\n",
        "            # Wrap forward passes in autocast\n",
        "            with torch.amp.autocast('cuda'):\n",
        "                # Generate refined images\n",
        "                refined_images = generator(coarse_output, masked_images, masks[:, 0:1])\n",
        "\n",
        "                # Discriminator predictions\n",
        "                real_pred = discriminator(real_images)\n",
        "                fake_pred = discriminator(refined_images.detach())\n",
        "\n",
        "                # Hinge loss\n",
        "                d_loss = hinge_loss_d(real_pred, fake_pred)\n",
        "\n",
        "            # Use scaler for backward pass\n",
        "            d_scaler.scale(d_loss).backward()\n",
        "            d_scaler.step(d_optimizer)\n",
        "            d_scaler.update()\n",
        "\n",
        "            # ==================\n",
        "            # Train Generator\n",
        "            # ==================\n",
        "            # Train generator every 1 discriminator steps\n",
        "            # Modified loss to heavily prioritize hole improvement\n",
        "            if batch_idx % 1 == 0:\n",
        "                g_optimizer.zero_grad()\n",
        "\n",
        "                with torch.amp.autocast('cuda'):\n",
        "                    refined_images = generator(coarse_output, masked_images, masks[:, 0:1])\n",
        "                    fake_pred = discriminator(refined_images)\n",
        "\n",
        "                    # AGGRESSIVE HOLE FOCUS:\n",
        "                    hole_mask = 1 - masks\n",
        "                    valid_mask = masks\n",
        "\n",
        "                    # 1. Adversarial - let it be stronger for realism\n",
        "                    g_adv_loss = hinge_loss_g(fake_pred) * 0.1\n",
        "\n",
        "                    # 2. Hole-only reconstruction (PRIMARY LOSS)\n",
        "                    g_hole_loss = l1_loss(refined_images * hole_mask, real_images * hole_mask) * 200  # HUGE weight\n",
        "\n",
        "                    # 3. Perceptual loss ONLY in holes\n",
        "                    g_perc_hole = perceptual_loss(refined_images * hole_mask, real_images * hole_mask) * 1.0\n",
        "\n",
        "                    # 4. Edge/boundary loss for better blending\n",
        "                    dilated_mask = F.max_pool2d(1 - masks[:, 0:1], 5, stride=1, padding=2)\n",
        "                    boundary = dilated_mask - (1 - masks[:, 0:1])\n",
        "                    g_boundary_loss = l1_loss(refined_images * boundary, real_images * boundary) * 50\n",
        "\n",
        "                    # 5. Small penalty for changing non-hole regions\n",
        "                    g_preserve_loss = l1_loss(refined_images * valid_mask, coarse_output * valid_mask) * 10\n",
        "\n",
        "                    # Total loss focuses on improving holes\n",
        "                    g_loss = g_adv_loss + g_hole_loss + g_perc_hole + g_boundary_loss + g_preserve_loss\n",
        "\n",
        "                # Use scaler for backward pass\n",
        "                g_scaler.scale(g_loss).backward()\n",
        "                g_scaler.step(g_optimizer)\n",
        "                g_scaler.update()\n",
        "\n",
        "                # Update residual weight (optional)\n",
        "                generator.residual_weight.data.clamp_(0.01, 0.1)\n",
        "\n",
        "            # Update progress bar\n",
        "            epoch_g_loss += g_loss.item()\n",
        "            epoch_d_loss += d_loss.item()\n",
        "            pbar.set_postfix({\n",
        "                'G': f'{g_loss.item():.4f}',\n",
        "                'D': f'{d_loss.item():.4f}',\n",
        "                'α': f'{generator.residual_weight.item():.3f}'\n",
        "            })\n",
        "\n",
        "        # Validation\n",
        "        if epoch % 5 == 0:\n",
        "            val_psnr = validate_gan(generator, cnn_model, val_loader, device)\n",
        "            history['val_psnr'].append(val_psnr)\n",
        "            print(f\"\\nValidation PSNR: {val_psnr:.2f} dB\")\n",
        "\n",
        "            # Save sample images\n",
        "            save_samples(generator, cnn_model, val_loader, epoch, device)\n",
        "\n",
        "        # Save checkpoint with scaler states\n",
        "        if epoch % 10 == 0:\n",
        "            torch.save({\n",
        "                'generator': generator.state_dict(),\n",
        "                'discriminator': discriminator.state_dict(),\n",
        "                'g_optimizer': g_optimizer.state_dict(),\n",
        "                'd_optimizer': d_optimizer.state_dict(),\n",
        "                'g_scaler': g_scaler.state_dict(),  # Save scaler state\n",
        "                'd_scaler': d_scaler.state_dict(),  # Save scaler state\n",
        "                'epoch': epoch\n",
        "            }, f'gan_checkpoint_epoch_{epoch}.pth')\n",
        "\n",
        "        history['g_loss'].append(epoch_g_loss / len(train_loader))\n",
        "        history['d_loss'].append(epoch_d_loss / len(train_loader))\n",
        "\n",
        "    return history\n",
        "\n",
        "# ============================================\n",
        "# 5. VALIDATION AND INFERENCE\n",
        "# ============================================\n",
        "\n",
        "def validate_gan(generator, cnn_model, val_loader, device):\n",
        "    \"\"\"Calculate validation metrics with mixed precision\"\"\"\n",
        "    generator.eval()\n",
        "    total_psnr = 0\n",
        "    count = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            real_images = batch.to(device)\n",
        "\n",
        "            # Add autocast for validation too\n",
        "            with torch.amp.autocast('cuda'):\n",
        "                masked_images, masks = create_mask(real_images, mask_percentage=0.025)\n",
        "                masks = masks.to(device)\n",
        "\n",
        "                cnn_input = torch.cat([masked_images, masks[:, 0:1]], dim=1)\n",
        "                coarse_output = cnn_model(cnn_input)\n",
        "\n",
        "                refined_images = generator(coarse_output, masked_images, masks[:, 0:1])\n",
        "\n",
        "            # Calculate metrics in FP32 (outside autocast)\n",
        "            mse = F.mse_loss((refined_images + 1) / 2, (real_images + 1) / 2)\n",
        "            psnr = 20 * torch.log10(torch.tensor(1.0)) - 10 * torch.log10(mse)\n",
        "\n",
        "            total_psnr += psnr.item() * real_images.size(0)\n",
        "            count += real_images.size(0)\n",
        "\n",
        "    return total_psnr / count\n",
        "\n",
        "def save_samples(generator, cnn_model, val_loader, epoch, device):\n",
        "    \"\"\"Save sample images\"\"\"\n",
        "    generator.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        batch = next(iter(val_loader))\n",
        "        real_images = batch[:4].to(device)\n",
        "\n",
        "        # Create masks and get CNN predictions\n",
        "        masked_images, masks = create_mask(real_images, mask_percentage=0.025)\n",
        "        masks = masks.to(device)\n",
        "\n",
        "        cnn_input = torch.cat([masked_images, masks[:, 0:1]], dim=1)\n",
        "        coarse_output = cnn_model(cnn_input)\n",
        "\n",
        "        # Generate refined images\n",
        "        refined_images = generator(coarse_output, masked_images, masks[:, 0:1])\n",
        "\n",
        "        # Create comparison grid\n",
        "        comparison = torch.cat([\n",
        "            (real_images + 1) / 2,\n",
        "            (masked_images + 1) / 2,\n",
        "            (coarse_output + 1) / 2,\n",
        "            (refined_images + 1) / 2\n",
        "        ], dim=0)\n",
        "\n",
        "        save_image(comparison, f'gan_samples_epoch_{epoch}.png', nrow=4)\n",
        "\n",
        "# ============================================\n",
        "# 6. INFERENCE FUNCTION\n",
        "# ============================================\n",
        "\n",
        "def inference_gan(generator, cnn_model, image, mask, device):\n",
        "    \"\"\"Run inference with the trained GAN\"\"\"\n",
        "    generator.eval()\n",
        "    cnn_model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Get CNN prediction\n",
        "        masked_image = image * mask\n",
        "        cnn_input = torch.cat([masked_image, mask[:, 0:1]], dim=1)\n",
        "        coarse_output = cnn_model(cnn_input)\n",
        "\n",
        "        # Refine with GAN\n",
        "        refined = generator(coarse_output, masked_image, mask[:, 0:1])\n",
        "\n",
        "        # Ensure unmasked regions are preserved\n",
        "        final_output = refined * (1 - mask) + image * mask\n",
        "\n",
        "        return final_output, coarse_output"
      ],
      "metadata": {
        "id": "f2-P0hTq05o4"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# USAGE\n",
        "# ============================================\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Initialize models\n",
        "generator = RefinementGenerator(in_channels=7, out_channels=3).to(device)\n",
        "discriminator = MultiscaleDiscriminator(in_channels=3).to(device)\n",
        "\n",
        "# Load your pre-trained CNN\n",
        "cnn_model = UNetSR().to(device)  # Use the same initialization as training!\n",
        "\n",
        "# Load and fix the state dict\n",
        "cnn_state_dict = torch.load('/content/drive/MyDrive/ColabNotebooks/Vision/inpainting/final_cnn_model.pth', map_location=device)\n",
        "\n",
        "# Remove _orig_mod. prefix if it exists\n",
        "if any(k.startswith('_orig_mod.') for k in cnn_state_dict.keys()):\n",
        "    cnn_state_dict = {k.replace('_orig_mod.', ''): v for k, v in cnn_state_dict.items()}\n",
        "\n",
        "# Now load the fixed state dict\n",
        "cnn_model.load_state_dict(cnn_state_dict)\n",
        "\n",
        "# Set to eval and freeze\n",
        "cnn_model.eval()\n",
        "for param in cnn_model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "print(\"✅ CNN loaded successfully\")\n",
        "\n",
        "# Train\n",
        "history = train_gan(\n",
        "    generator,\n",
        "    discriminator,\n",
        "    cnn_model,\n",
        "    train_loader=gan_dataloader,\n",
        "    val_loader=val_dataloader,\n",
        "    num_epochs=80,\n",
        "    device=device\n",
        ")\n",
        "\n",
        "# Save final models\n",
        "torch.save(generator.state_dict(), 'gan_generator_final.pth')\n",
        "torch.save(discriminator.state_dict(), 'gan_discriminator_final.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232,
          "referenced_widgets": [
            "d89840c266e24ef78d7d65a196c4ffa4",
            "a865c737e2944dbc9da8e5a4a57051d0",
            "da949447e93a414ca2a3d6e3788be4a5",
            "e8694e6923434f3eb823442b51982d82",
            "cf257cac8c5f4b298882f64a4162cd52",
            "383a7593d3e346df92573c3fa159de4c",
            "8e2d1fe51df84a5ea9343e6d13a13136",
            "c334e8ca0ecc47ad8f4788d357111218",
            "de689220d48e474a83e2c6a34b01f692",
            "ab82449e4585468c8ce4a21f2d2435a9",
            "a0f45abef42a45e48ca664e2b36a0df9",
            "ca2a5cb20d2948ad90b828d73f40c2c7",
            "7e4d2d1e5a4c4c4fac427f46e9f2bc7f",
            "9661e5d1c15c4635bff6d946795a5672",
            "d9bc8fd1639e484caeac3dd248fe7543",
            "b342c35e7fc84be1b01828cf07881316",
            "37a11764082c43dabd4437c67d5e0424",
            "0752aaf4e2744a91bebe4eb994e6456d",
            "aaaa3bf2782f404481b3edadf09088c1",
            "2c6b38d24b034fdfae1e3d25f39cc70c",
            "b48f03043dcf458dab661bf00572f76c",
            "e05f8bcae3f646e9ad2a9b218b359e2b",
            "45664f4e8442455c8a0873002c6eb5f6",
            "7c78c99d540f478e83479399029e33be",
            "d502220102094423a325299cd88dd30a",
            "6116ed8854f442c18a2f3c5635353ec1",
            "f212b1bcbe4c4f3ba3589419ddf9b877",
            "76f37db6c413471b80ccfe5c44d9c875",
            "1754c361997841e9841a5dfaae392d5c",
            "cef34c12618d4c9383b3c2423cd252a1",
            "22323f72217746d799781b33a6e745c9",
            "623b6937679a4040b2a371b92113a1cf",
            "de45bcc2b9c346dfad2e34bb3fb6b296",
            "706ef876220c4fd8a67a21d2fe903d27",
            "c4cbef4a0aac4587b1e193e27f99e5e1",
            "b0d49e53f21447b9835c36bc9d8f6e8c",
            "5572034d0bf14ca4adb600f8feff367a",
            "2d40e6ce3d8b4144abab1929aeefb3d8",
            "211a8fe7d3594b28b4f52f0938cc1bc1",
            "50cfa09b5ea94930895dc5a8a6f0557a",
            "a43feec37524494da424f9894444a88e",
            "ecc97477900e4fedb27645ad5b8818c1",
            "24bb2370f911479283209f76e5682ec6",
            "5922d903d32c4a74931eb8e4134e01dc"
          ]
        },
        "id": "xhFMxxVK08LQ",
        "outputId": "877bb301-b670-4e31-bf4f-8453a37c17ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ CNN loaded successfully\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to /root/.cache/torch/hub/checkpoints/vgg19-dcbb9e9d.pth\n",
            "100%|██████████| 548M/548M [00:02<00:00, 233MB/s]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 1/80:   0%|          | 0/31 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d89840c266e24ef78d7d65a196c4ffa4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Validation PSNR: 26.85 dB\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 2/80:   0%|          | 0/31 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ca2a5cb20d2948ad90b828d73f40c2c7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 3/80:   0%|          | 0/31 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "45664f4e8442455c8a0873002c6eb5f6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 4/80:   0%|          | 0/31 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "706ef876220c4fd8a67a21d2fe903d27"
            }
          },
          "metadata": {}
        }
      ]
    }
  ]
}